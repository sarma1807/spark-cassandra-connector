// *** FOR SparkSQL with Datasets METHOD ***

import org.apache.spark.SparkContext
import org.apache.spark.SparkConf
import com.datastax.spark.connector._
import com.datastax.spark.connector.cql.CassandraConnector
import org.apache.spark.sql.cassandra._
import org.apache.spark.sql.{Dataset, SaveMode}
import sys.process._

// you can configure multiple catalogs for same cluster or different clusters
// with multiple catalogs it is possible to throttle read/write speeds to same cluster
// with multiple catalogs it is possible copy data between them
spark.conf.set("spark.sql.catalog.cass_db_1", "com.datastax.spark.connector.datasource.CassandraCatalog")
spark.conf.set("spark.sql.defaultCatalog", "cass_db_1")

// <IP_ADDRESS_LIST>
// provide multiple cassandra contact points from same data center
// format : comma separated : IP1,IP2,IP3 or IP1:PORT,IP2:PORT,IP3:PORT
spark.conf.set("spark.sql.catalog.cass_db_1.spark.cassandra.connection.host", "192.168.1.151,192.168.1.152")

// need following for cassandra authentication
spark.conf.set("spark.sql.catalog.cass_db_1.spark.cassandra.auth.username", "thor")
spark.conf.set("spark.sql.catalog.cass_db_1.spark.cassandra.auth.password", "oracle")

// spark.cassandra.connection.keepAliveMS : for unused connections : default = 1 hour
spark.conf.set("spark.sql.catalog.cass_db_1.spark.cassandra.connection.keepAliveMS", "600000")
// spark.cassandra.read.timeoutMS : default = 2 minutes : timeout for a READ to return from cassandra
spark.conf.set("spark.sql.catalog.cass_db_1.spark.cassandra.read.timeoutMS", "600000")

// consistency level : ALL / EACH_QUORUM / QUORUM / LOCAL_QUORUM / ONE / TWO / THREE / LOCAL_ONE / ANY

// input = reading data from cassandra
spark.conf.set("spark.sql.catalog.cass_db_1.spark.cassandra.input.consistency.level", "LOCAL_QUORUM")
// spark.conf.set("spark.sql.catalog.cass_db_1.spark.cassandra.input.throughputMBPerSec", "1")

// output = writing data to cassandra
spark.conf.set("spark.sql.catalog.cass_db_1.spark.cassandra.output.consistency.level", "TWO")
// spark.conf.set("spark.sql.catalog.cass_db_1.spark.cassandra.output.throughputMBPerSec", "1")


// some more interesting parameters
// spark.cassandra.connection.localDC
// spark.cassandra.connection.port
// spark.cassandra.connection.timeoutMS	: default = 5 seconds : timeout to get connection to cassandra node


// print list of included jars + context conf settings
spark.sparkContext.listJars.foreach(println)
spark.conf.getAll.foreach(println)
"date".!


