// *** FOR SparkSQL with DataFrames METHOD ***

import org.apache.spark.SparkContext
import org.apache.spark.SparkConf
import com.datastax.spark.connector._
import com.datastax.spark.connector.cql.CassandraConnector
import org.apache.spark.sql.cassandra._
import org.apache.spark.sql.{Dataset, SaveMode}
import sys.process._

// provide multiple cassandra contact points from same data center
spark.conf.set("spark.cassandra.connection.host", "192.168.1.151,192.168.1.152")
spark.conf.set("spark.sql.catalog.cass_db1", "com.datastax.spark.connector.datasource.CassandraCatalog")
spark.conf.set("spark.sql.catalog.cass_db1.spark.cassandra.connection.host", "192.168.1.151,192.168.1.152")
// need following for cassandra authentication
spark.conf.set("spark.cassandra.auth.username", "thor")
spark.conf.set("spark.cassandra.auth.password", "oracle")
// need following for cassandra timeouts - need high values to finish large jobs
spark.conf.set("spark.cassandra.connection.keepAliveMS", "300000")
spark.conf.set("spark.cassandra.connection.timeoutMS", "300000")
spark.conf.set("spark.cassandra.read.timeoutMS", "300000")
spark.conf.set("spark.cassandra.input.split.sizeInMB", "512")
// consistency level : ALL / EACH_QUORUM / QUORUM / LOCAL_QUORUM / ONE / TWO / THREE / LOCAL_ONE / ANY
spark.conf.set("spark.cassandra.input.consistency.level", "LOCAL_QUORUM")
spark.conf.set("spark.cassandra.output.consistency.level", "LOCAL_QUORUM")

// print list of included jars + context conf settings
spark.sparkContext.listJars.foreach(println)
spark.conf.getAll.foreach(println)
"date".!

